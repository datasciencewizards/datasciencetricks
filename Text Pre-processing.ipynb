{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "stemmer = PorterStemmer() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating string variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"Welcome to DSW Youtube Channel 10<ok>.DSW stAnds for #Data Science @Wizards.We are welcoming you to Our family\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "welcome to dsw youtube channel 10<ok>.dsw stands for #data science @wizards.we are welcoming you to our family\n"
     ]
    }
   ],
   "source": [
    "#Converting to lowercase to make it unified\n",
    "sentence = sentence.lower()  \n",
    "print (sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compiling regular expression\n",
    "cleanr = re.compile('<.*?>')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Substitution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "welcome to dsw youtube channel 10.dsw stands for #data science @wizards.we are welcoming you to our family\n"
     ]
    }
   ],
   "source": [
    "#Substituting compiled pattern with blank space in the string\n",
    "cleantext = re.sub(cleanr, '', sentence)  \n",
    "print (cleantext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "welcome to dsw youtube channel .dsw stands for #data science @wizards.we are welcoming you to our family\n"
     ]
    }
   ],
   "source": [
    "#Substituting numbers with blank space\n",
    "rem_num = re.sub('[0-9]+', '', cleantext)  #Substituting numbers with blank space\n",
    "print (rem_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['welcome', 'to', 'dsw', 'youtube', 'channel', 'dsw', 'stands', 'for', 'data', 'science', 'wizards', 'we', 'are', 'welcoming', 'you', 'to', 'our', 'family']\n"
     ]
    }
   ],
   "source": [
    "#Creating a reference variable for Class RegexpTokenizer\n",
    "tokenizer = RegexpTokenizer(r'\\w+')  \n",
    "    \n",
    "#Using tokenize method on processed data\n",
    "tokens = tokenizer.tokenize(rem_num) \n",
    "\n",
    "print (tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['welcome', 'dsw', 'youtube', 'channel', 'dsw', 'stands', 'data', 'science', 'wizards', 'welcoming', 'family']\n"
     ]
    }
   ],
   "source": [
    "#Removing stopwords\n",
    "filtered_words = [w for w in tokens if len(w) > 2 if not w in stopwords.words('english')] \n",
    "\n",
    "print (filtered_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['welcom', 'dsw', 'youtub', 'channel', 'dsw', 'stand', 'data', 'scienc', 'wizard', 'welcom', 'famili']\n"
     ]
    }
   ],
   "source": [
    "#Stemming words after tokenizing\n",
    "stem_words=[stemmer.stem(w) for w in filtered_words]  \n",
    "\n",
    "print (stem_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
